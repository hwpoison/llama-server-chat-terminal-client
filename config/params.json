///////////////////////////////////////////
// All profiles related to model parameters
// Usage: https://github.com/ggerganov/llama.cpp/tree/master/examples/server
///////////////////////////////////////////
{
	"params_profiles":{
	    "creative": {
	        "mirostat": 0,
	        "mirostat_tau": 5,
	        "mirostat_eta": 0.1,
	        "frecuency_penalty": 0,
	        "top_k": 40,
	        "top_p": 0.5,
	        "stop":["</s>","<|end|>","<|eot_id|>","<|end_of_text|>","<|im_end|>","<|EOT|>","<|END_OF_TURN_TOKEN|>","<|end_of_turn|>","<|endoftext|>","assistant","user"],
	        "typical_p": 1,
	        "tfz_z": 1,
	        "n_probs":0,
	        "presence_penalty":0,
	        "repeat_last_n": 256,
	        "repeat_penalty": 1.18,
	        "temperature": 0.7,
	        "n_predict": 250,
	        "stream": true,
	        "slot_id":0
	    },
	    "precision": {
	        "frecuency_penalty": 0,
	        "top_k": 40,
	        "top_p": 0.2,
	        "stop":["</s>", "<|"],
	        "n_probs":0,
	        "repeat_penalty": 1.18,
	        "temperature": 0.0,
	        "n_predict": 250,
	        "stream": true,
	        "slot_id":0
	    },
	    "without_stream": {
	        "mirostat": 2,
	        "mirostat_tau": 5,
	        "mirostat_eta": 0.1,
	        "frecuency_penalty": 0,
	        "top_k": 40,
	        "top_p": 0.5,
	        "typical_p": 1,
	        "tfz_z": 1,
	        "seed":3443,
	        "repeat_last_n": 256,
	        "repeat_penalty": 1.18,
	        "temperature": 0.8,
	        "n_predict": 100,
	        "stream": false
	    }
	}
}